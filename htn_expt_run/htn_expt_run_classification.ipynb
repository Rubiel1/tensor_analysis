{
 "metadata": {
  "name": "",
  "signature": "sha256:726bfacb421b917977baece3c77d5df25a07f7888fa533641aeeb028ceb20edf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## prerequisites\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import operator\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import interp\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import cross_validation \n",
      "from sklearn import datasets\n",
      "from sklearn import linear_model\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "from sklearn import svm\n",
      "from sklearn import ensemble\n",
      "\n",
      "tensor_input = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_tensors/htn-tensor-subsetforanalysis-20140811-{0}.dat'\n",
      "CODE_DIR = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/experiment_code/'\n",
      "marble_output_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/marble_output_files/'\n",
      "save_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/analyzeTensors_runClassification/'\n",
      "mht_feature_csvfile = '/nv/pcoc1/rchen87/download_from_dropbox_ANALYSIS_FULL_DATASET/data/new_data_20140416/Data_curated_RC_2014may/df_BPSTATUS_Phenotype_BMI_ECG_EGFR_BPCHANGE.csv'\n",
      "l_mht_patients_file = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_process/l_pts_used_MHT_outcome_analysis.txt'\n",
      "\n",
      "\n",
      "#load MHT subset CSV file\n",
      "with open(l_mht_patients_file) as f:\n",
      "    l_pts_used_MHT_outcome_analysis = f.read().splitlines()\n",
      "l_pts_used_MHT_outcome_analysis = [int(n) for n in l_pts_used_MHT_outcome_analysis]\n",
      "l_pts_used_MHT_outcome_analysis = np.sort(l_pts_used_MHT_outcome_analysis)\n",
      "df_mht_features = pd.read_csv(mht_feature_csvfile)\n",
      "df_mht_features_SUBSET = df_mht_features[df_mht_features.RUID.isin(l_pts_used_MHT_outcome_analysis)] #use THIS as the subset of MHT patients in most recently submitted JAMIA paper\n",
      "df_mht_features_SUBSET = df_mht_features_SUBSET.sort([\"RUID\"], ascending=[1])\n",
      "\n",
      "#load required modules:                                                                                                                                                                                                                                                                                           \n",
      "print \"loading required modules\"\n",
      "\n",
      "execfile( CODE_DIR + 'setup_python_env.py')\n",
      "pheWAS_xls_file = CODE_DIR + 'ICD9-2-PheWAS.xls'\n",
      "\n",
      "\n",
      "#create output folder if it does not exist                                                                                                                                                                                                                                                                        \n",
      "if not os.path.exists(save_folder):\n",
      "    os.makedirs(save_folder)\n",
      "\n",
      "############################################################################################################## \n",
      "\n",
      "#load pheWAS dictionary                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "xls = pd.ExcelFile(pheWAS_xls_file)\n",
      "df_pheWAS = xls.parse(xls.sheet_names[0])\n",
      "\n",
      "d_jdrange_lookup = dict(zip(list(df_pheWAS.JD_X_RANGE), list(df_pheWAS.JD_X_NAME)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading required modules\n"
       ]
      }
     ],
     "prompt_number": 259
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load the tensor #######                                                                                                                                                                                                                                                                                        \n",
      "loaded_X, loaded_axisDict, loaded_classDict = tensorIO.loadSingleTensor(tensor_input)\n",
      "\n",
      "# the following are common to all ranges of gamma\n",
      "l_pts = loaded_axisDict[0].keys()\n",
      "l_jdrange = loaded_axisDict[1].keys()\n",
      "l_meds= loaded_axisDict[2].keys()\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load marble results -- for a range of gammas\n",
      "\n",
      "#specify which gamma\n",
      "l_gammas = l_gammas = [0.01 * x for x in range(1,16)]\n",
      "\n",
      "#define classification models\n",
      "random_state = np.random.RandomState(0)\n",
      "model_logistic_l2 = linear_model.LogisticRegression(penalty='l2')\n",
      "model_svm_linear = svm.SVC(kernel='linear', probability=True,\n",
      "                     random_state=random_state)\n",
      "model_randForest = ensemble.RandomForestClassifier(100)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 252
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loop thru all gammas in the l_gammas, load the tensor factor data, and run classification\n",
      "\n",
      "classifier_to_use = ('randForest', model_randForest) #tuple, first entry = name describing classifier, second entry = defined model (see above)\n",
      "s_outcome_description = '_MAPDECREASEBY2'\n",
      "\n",
      "for thisgamma in l_gammas:\n",
      "    #string for python pickle file (to read from) based upon gamma                                                                                                                                                                                                                                                                      \n",
      "    gammaForTF_used = [0.001, thisgamma, thisgamma]\n",
      "    gamma_str = '_gamma'\n",
      "    for num in gammaForTF_used:\n",
      "        gamma_str = gamma_str + '-' + str(num)\n",
      "    gamma_str = gamma_str + '.pickle'\n",
      "\n",
      "    filename_tensorFactors_thisgamma_REG = marble_output_folder + \"pheno_htn_subset_analyzed_REG\" + gamma_str\n",
      "    filename_tensorFactors_thisgamma_AUG = marble_output_folder + \"pheno_htn_subset_analyzed_AUG\" + gamma_str\n",
      "    filename_Yinfo_thisgamma = marble_output_folder + \"Yinfo_htn_subset_analyzed\" + gamma_str\n",
      "\n",
      "    ##read in the pickles:                                                                                                                                                                                                                                                                                            \n",
      "    matrix_pkl = open(filename_tensorFactors_thisgamma_REG, \"rb\")\n",
      "    pheno_htn_subset_analyzed_REG_withGamma = pickle.load(matrix_pkl)\n",
      "    matrix_pkl.close()\n",
      "\n",
      "    matrix_pkl = open(filename_tensorFactors_thisgamma_AUG, \"rb\")\n",
      "    pheno_htn_subset_analyzed_AUG_withGamma = pickle.load(matrix_pkl)\n",
      "    matrix_pkl.close()\n",
      "\n",
      "    matrix_pkl = open(filename_Yinfo_thisgamma, \"rb\")\n",
      "    Yinfo_htn_subset_analyzed_withGamma = pickle.load(matrix_pkl)\n",
      "    matrix_pkl.close()\n",
      "    \n",
      "    #tensor with the 50 phenotypes that were computed\n",
      "    ktensor_phenotypes = pheno_htn_subset_analyzed_REG_withGamma[0]\n",
      "\n",
      "    num_pt = ktensor_phenotypes.shape[0]\n",
      "    num_jdrange = ktensor_phenotypes.shape[1]\n",
      "    num_med = ktensor_phenotypes.shape[2]\n",
      "\n",
      "    #sort phenotypes by lambda values:                                                                                                                                                                                                                                                                                \n",
      "    d_lambda_phenoNumber = OrderedDict(zip( list(range(ktensor_phenotypes.R)),\n",
      "                                        list(ktensor_phenotypes.lmbda)\n",
      "                                        ))\n",
      "    l_phenoNumbers_sorted_by_lambda = [tup[0] for tup in sorted(d_lambda_phenoNumber.iteritems(), key=operator.itemgetter(1))][::-1]  #get a sorted list of phenotype numbers, which are sorted by using the operator.itemgetter                                                                                      \n",
      "\n",
      "    #feature_matrix and target \n",
      "    feature_matrix_phenos = ktensor_phenotypes.U[0]\n",
      "\n",
      "    feature_matrix_phenos_binary = feature_matrix_phenos.copy()\n",
      "    feature_matrix_phenos_binary[feature_matrix_phenos_binary.nonzero()] = 1\n",
      "\n",
      "    target_vals = np.array(loaded_classDict.values())\n",
      "\n",
      "    #do CV with classification with sklearn module\n",
      "\n",
      "    #define X, y\n",
      "    X = feature_matrix_phenos_binary\n",
      "    y = target_vals\n",
      "\n",
      "    #determind CV folds\n",
      "    cv_folds_indexnumbers = cross_validation.StratifiedKFold(y, n_folds=10)\n",
      "\n",
      "    #define metrics\n",
      "    mean_tpr = 0.0\n",
      "    mean_fpr = np.linspace(0, 1, 100)\n",
      "    all_tpr = []\n",
      "\n",
      "    #OPEN FIGURE HANDLE\n",
      "    fig = plt.figure(thisgamma)\n",
      "    fig.set_size_inches(8,8)\n",
      "\n",
      "    for i, (train_index, test_index) in enumerate(cv_folds_indexnumbers):\n",
      "        #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "        X_train, X_test = feature_matrix_phenos[train_index], feature_matrix_phenos[test_index]\n",
      "        y_train, y_test = target_vals[train_index], target_vals[test_index]\n",
      "\n",
      "        probas_ = classifier_to_use[1].fit(X_train, y_train).predict_proba(X_test)\n",
      "        # Compute ROC curve and area the curve\n",
      "        fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
      "        mean_tpr += interp(mean_fpr, fpr, tpr)\n",
      "        mean_tpr[0] = 0.0\n",
      "        roc_auc = auc(fpr, tpr)\n",
      "        #add plot to figure\n",
      "        plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
      "\n",
      "    #add to figure\n",
      "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
      "\n",
      "    #calculate mean TPR, AUC\n",
      "    mean_tpr /= len(cv_folds_indexnumbers)\n",
      "    mean_tpr[-1] = 1.0\n",
      "    mean_auc = auc(mean_fpr, mean_tpr)\n",
      "\n",
      "    #add supporting legends to figure\n",
      "    plt.plot(mean_fpr, mean_tpr, 'k--',\n",
      "             label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
      "\n",
      "    plt.xlim([-0.05, 1.05])\n",
      "    plt.ylim([-0.05, 1.05])\n",
      "    plt.xlabel('False Positive Rate')\n",
      "    plt.ylabel('True Positive Rate')\n",
      "    plt.title('ROC: 10-fold CV' +  classifier_to_use[0] + '; ' + s_target_description + '; Gamma='+ \"-\".join([str(g) for g in gammaForTF_used]))\n",
      "    plt.legend(loc=\"lower right\")\n",
      "    #save figure\n",
      "    save_filename = 'htn_marble_classification_' + classifier_to_use[0] + s_target_description + '_gamma_' + \"-\".join([str(g) for g in gammaForTF_used]) + '.png'\n",
      "    fig.savefig(save_folder + save_filename)\n",
      "    plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df_mht_features_SUBSET.tail()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "html": [
        "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
        "<table border=\"1\" class=\"dataframe\">\n",
        "  <thead>\n",
        "    <tr style=\"text-align: right;\">\n",
        "      <th></th>\n",
        "      <th>RUID</th>\n",
        "      <th>BP_STATUS</th>\n",
        "      <th>DM_TX</th>\n",
        "      <th>CHF_TX</th>\n",
        "      <th>SEX</th>\n",
        "      <th>DOB</th>\n",
        "      <th>DOD</th>\n",
        "      <th>ETHNICITY</th>\n",
        "      <th>RACE</th>\n",
        "      <th>MHT_STATUS</th>\n",
        "      <th>ENGAGE_DATE</th>\n",
        "      <th>ENROLL_DATE</th>\n",
        "      <th>WHITE</th>\n",
        "      <th>BLACK</th>\n",
        "      <th>ASIAN</th>\n",
        "      <th>HISPANIC</th>\n",
        "      <th>AGE_ENGAGE</th>\n",
        "      <th>AGE_DEATH</th>\n",
        "      <th>MHT_Indicator</th>\n",
        "      <th>AVG_WEIGHT</th>\n",
        "      <th></th>\n",
        "    </tr>\n",
        "  </thead>\n",
        "  <tbody>\n",
        "    <tr>\n",
        "      <th>459 </th>\n",
        "      <td> 99748163</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> F</td>\n",
        "      <td> 1930-07-11 00:00:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2011-11-27 00:00:00</td>\n",
        "      <td> 2011-12-25 00:00:00</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 81.435616</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1</td>\n",
        "      <td>  95.391818</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1797</th>\n",
        "      <td> 99754761</td>\n",
        "      <td>-1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> F</td>\n",
        "      <td> 1935-04-16 00:00:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2012-09-04 00:00:00</td>\n",
        "      <td> 2012-08-29 00:00:00</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 77.441096</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1</td>\n",
        "      <td>  57.931011</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1399</th>\n",
        "      <td> 99785560</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> 1</td>\n",
        "      <td> M</td>\n",
        "      <td> 1941-09-17 00:00:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2011-04-16 00:00:00</td>\n",
        "      <td> 2011-04-23 00:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 69.624658</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1</td>\n",
        "      <td> 102.074495</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>1858</th>\n",
        "      <td> 99787789</td>\n",
        "      <td>-1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> F</td>\n",
        "      <td> 1945-09-28 00:00:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 3</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2011-05-10 00:00:00</td>\n",
        "      <td> 2011-05-03 00:00:00</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 65.657534</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1</td>\n",
        "      <td>  81.148058</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "    <tr>\n",
        "      <th>5888</th>\n",
        "      <td> 99971945</td>\n",
        "      <td>-1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> M</td>\n",
        "      <td> 1971-07-12 00:00:00</td>\n",
        "      <td> NaN</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 2012-07-09 00:00:00</td>\n",
        "      <td> 2012-06-27 00:00:00</td>\n",
        "      <td> 0</td>\n",
        "      <td> 1</td>\n",
        "      <td> 0</td>\n",
        "      <td> 0</td>\n",
        "      <td> 41.021918</td>\n",
        "      <td>NaN</td>\n",
        "      <td> 1</td>\n",
        "      <td> 120.674211</td>\n",
        "      <td>...</td>\n",
        "    </tr>\n",
        "  </tbody>\n",
        "</table>\n",
        "<p>5 rows \u00d7 53 columns</p>\n",
        "</div>"
       ],
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 261,
       "text": [
        "          RUID  BP_STATUS  DM_TX  CHF_TX SEX                  DOB  DOD  \\\n",
        "459   99748163          1      0       0   F  1930-07-11 00:00:00  NaN   \n",
        "1797  99754761         -1      0       0   F  1935-04-16 00:00:00  NaN   \n",
        "1399  99785560          1      1       1   M  1941-09-17 00:00:00  NaN   \n",
        "1858  99787789         -1      0       0   F  1945-09-28 00:00:00  NaN   \n",
        "5888  99971945         -1      0       0   M  1971-07-12 00:00:00  NaN   \n",
        "\n",
        "      ETHNICITY  RACE  MHT_STATUS          ENGAGE_DATE          ENROLL_DATE  \\\n",
        "459           0     3           1  2011-11-27 00:00:00  2011-12-25 00:00:00   \n",
        "1797          0     3           1  2012-09-04 00:00:00  2012-08-29 00:00:00   \n",
        "1399          0     0           1  2011-04-16 00:00:00  2011-04-23 00:00:00   \n",
        "1858          0     3           1  2011-05-10 00:00:00  2011-05-03 00:00:00   \n",
        "5888          0     0           1  2012-07-09 00:00:00  2012-06-27 00:00:00   \n",
        "\n",
        "      WHITE  BLACK  ASIAN  HISPANIC  AGE_ENGAGE  AGE_DEATH  MHT_Indicator  \\\n",
        "459       1      0      0         0   81.435616        NaN              1   \n",
        "1797      1      0      0         0   77.441096        NaN              1   \n",
        "1399      0      1      0         0   69.624658        NaN              1   \n",
        "1858      1      0      0         0   65.657534        NaN              1   \n",
        "5888      0      1      0         0   41.021918        NaN              1   \n",
        "\n",
        "      AVG_WEIGHT      \n",
        "459    95.391818 ...  \n",
        "1797   57.931011 ...  \n",
        "1399  102.074495 ...  \n",
        "1858   81.148058 ...  \n",
        "5888  120.674211 ...  \n",
        "\n",
        "[5 rows x 53 columns]"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "thisgamma"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "ERROR: Internal Python error in the inspect module.\n",
        "Below is the traceback from this internal error.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Traceback (most recent call last):\n",
        "  File \"/usr/local/packages/python/2.7.7/gcc-4.4.5/lib/python2.7/site-packages/ipython-2.1.0-py2.7.egg/IPython/core/ultratb.py\", line 776, in structured_traceback\n",
        "    records = _fixed_getinnerframes(etb, context, tb_offset)\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"/usr/local/packages/python/2.7.7/gcc-4.4.5/lib/python2.7/site-packages/ipython-2.1.0-py2.7.egg/IPython/core/ultratb.py\", line 230, in wrapped\n",
        "    return f(*args, **kwargs)\n",
        "  File \"/usr/local/packages/python/2.7.7/gcc-4.4.5/lib/python2.7/site-packages/ipython-2.1.0-py2.7.egg/IPython/core/ultratb.py\", line 259, in _fixed_getinnerframes\n",
        "    records  = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
        "  File \"/usr/local/packages/python/2.7.7/gcc-4.4.5/lib/python2.7/inspect.py\", line 1044, in getinnerframes\n",
        "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "  File \"/usr/local/packages/python/2.7.7/gcc-4.4.5/lib/python2.7/inspect.py\", line 1004, in getframeinfo\n",
        "    filename = getsourcefile(frame) or getfile(frame)\n",
        "  File \"/usr/local/packages/python/2.7.7/gcc-4.4.5/lib/python2.7/inspect.py\", line 454, in getsourcefile\n",
        "    if hasattr(getmodule(object, filename), '__loader__'):\n",
        "  File \"/usr/local/packages/python/2.7.7/gcc-4.4.5/lib/python2.7/inspect.py\", line 490, in getmodule\n",
        "    for modname, module in sys.modules.items():\n",
        "KeyboardInterrupt\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "\n",
        "Unfortunately, your original traceback can not be constructed.\n",
        "\n"
       ]
      },
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": ""
      }
     ],
     "prompt_number": 262
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}