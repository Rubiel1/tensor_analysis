{
 "metadata": {
  "name": "",
  "signature": "sha256:c1de3b6dcbc4b6085050e69363b71fc3ac6efff4ff778fa81df9c3ee7676b06a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## prerequisites\n",
      "\n",
      "import os\n",
      "import sys\n",
      "import operator\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "from scipy import interp\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn import cross_validation \n",
      "from sklearn import datasets\n",
      "from sklearn import linear_model\n",
      "from sklearn.metrics import roc_curve, auc\n",
      "\n",
      "tensor_input = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_tensors/htn-tensor-subsetforanalysis-20140811-{0}.dat'\n",
      "CODE_DIR = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/experiment_code/'\n",
      "marble_output_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/marble_output_files/'\n",
      "save_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/analyzeTensors_runClassification/'\n",
      "mht_feature_csvfile = '/nv/pcoc1/rchen87/download_from_dropbox_ANALYSIS_FULL_DATASET/data/new_data_20140416/Data_curated_RC_2014may/df_BPSTATUS_Phenotype_BMI_ECG_EGFR_BPCHANGE.csv'\n",
      "l_mht_patients_file = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_process/l_pts_used_MHT_outcome_analysis.txt'\n",
      "\n",
      "\n",
      "#load MHT subset CSV file\n",
      "with open(l_mht_patients_file) as f:\n",
      "    l_pts_used_MHT_outcome_analysis = f.read().splitlines()\n",
      "l_pts_used_MHT_outcome_analysis = [int(n) for n in l_pts_used_MHT_outcome_analysis]\n",
      "df_mht_features = pd.read_csv(mht_feature_csvfile)\n",
      "df_mht_features_SUBSET = df_mht_features[df_mht_features.RUID.isin(l_pts_used_MHT_outcome_analysis)] #use THIS as the subset of MHT patients in most recently submitted JAMIA paper\n",
      "\n",
      "\n",
      "#load required modules:                                                                                                                                                                                                                                                                                           \n",
      "print \"loading required modules\"\n",
      "\n",
      "execfile( CODE_DIR + 'setup_python_env.py')\n",
      "pheWAS_xls_file = CODE_DIR + 'ICD9-2-PheWAS.xls'\n",
      "\n",
      "\n",
      "#create output folder if it does not exist                                                                                                                                                                                                                                                                        \n",
      "if not os.path.exists(save_folder):\n",
      "    os.makedirs(save_folder)\n",
      "\n",
      "############################################################################################################## \n",
      "\n",
      "#load pheWAS dictionary                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "xls = pd.ExcelFile(pheWAS_xls_file)\n",
      "df_pheWAS = xls.parse(xls.sheet_names[0])\n",
      "\n",
      "d_jdrange_lookup = dict(zip(list(df_pheWAS.JD_X_RANGE), list(df_pheWAS.JD_X_NAME)))\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading required modules\n"
       ]
      }
     ],
     "prompt_number": 102
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load the tensor #######                                                                                                                                                                                                                                                                                        \n",
      "loaded_X, loaded_axisDict, loaded_classDict = tensorIO.loadSingleTensor(tensor_input)\n",
      "\n",
      "# the following are common to all ranges of gamma\n",
      "l_pts = loaded_axisDict[0].keys()\n",
      "l_jdrange = loaded_axisDict[1].keys()\n",
      "l_meds= loaded_axisDict[2].keys()\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## load marble results -- use the ones for gamma = 0.04\n",
      "\n",
      "#specify which gamma\n",
      "l_gammas = l_gammas = [0.01 * x for x in range(1,16)]\n",
      "\n",
      "# loop thru all gammas in the l_gammas, load the tensor factor data, and run classification\n",
      "\n",
      "\n",
      "thisgamma = 0.04\n",
      "\n",
      "#string for python pickle file (to read from) based upon gamma                                                                                                                                                                                                                                                                      \n",
      "gammaForTF_used = [0.001, thisgamma, thisgamma]\n",
      "gamma_str = '_gamma'\n",
      "for num in gammaForTF_used:\n",
      "    gamma_str = gamma_str + '-' + str(num)\n",
      "gamma_str = gamma_str + '.pickle'\n",
      "\n",
      "filename_tensorFactors_thisgamma_REG = marble_output_folder + \"pheno_htn_subset_analyzed_REG\" + gamma_str\n",
      "filename_tensorFactors_thisgamma_AUG = marble_output_folder + \"pheno_htn_subset_analyzed_AUG\" + gamma_str\n",
      "filename_Yinfo_thisgamma = marble_output_folder + \"Yinfo_htn_subset_analyzed\" + gamma_str\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##read in the pickles:                                                                                                                                                                                                                                                                                            \n",
      "matrix_pkl = open(filename_tensorFactors_thisgamma_REG, \"rb\")\n",
      "pheno_htn_subset_analyzed_REG_withGamma = pickle.load(matrix_pkl)\n",
      "matrix_pkl.close()\n",
      "\n",
      "matrix_pkl = open(filename_tensorFactors_thisgamma_AUG, \"rb\")\n",
      "pheno_htn_subset_analyzed_AUG_withGamma = pickle.load(matrix_pkl)\n",
      "matrix_pkl.close()\n",
      "\n",
      "matrix_pkl = open(filename_Yinfo_thisgamma, \"rb\")\n",
      "Yinfo_htn_subset_analyzed_withGamma = pickle.load(matrix_pkl)\n",
      "matrix_pkl.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#tensor with the 50 phenotypes that were computed\n",
      "ktensor_phenotypes = pheno_htn_subset_analyzed_REG_withGamma[0]\n",
      "\n",
      "num_pt = ktensor_phenotypes.shape[0]\n",
      "num_jdrange = ktensor_phenotypes.shape[1]\n",
      "num_med = ktensor_phenotypes.shape[2]\n",
      "\n",
      "#sort phenotypes by lambda values:                                                                                                                                                                                                                                                                                \n",
      "d_lambda_phenoNumber = OrderedDict(zip( list(range(ktensor_phenotypes.R)),\n",
      "                                    list(ktensor_phenotypes.lmbda)\n",
      "                                    ))\n",
      "l_phenoNumbers_sorted_by_lambda = [tup[0] for tup in sorted(d_lambda_phenoNumber.iteritems(), key=operator.itemgetter(1))][::-1]  #get a sorted list of phenotype numbers, which are sorted by using the operator.itemgetter                                                                                      \n",
      "\n",
      "#feature_matrix and target \n",
      "feature_matrix_phenos = ktensor_phenotypes.U[0]\n",
      "\n",
      "feature_matrix_phenos_binary = feature_matrix_phenos.copy()\n",
      "feature_matrix_phenos_binary[feature_matrix_phenos_binary.nonzero()] = 1\n",
      "\n",
      "target_vals = loaded_classDict.values()\n",
      "\n",
      "\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 160
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#do CV with classification with sklearn module\n",
      "\n",
      "#define X, y\n",
      "X = feature_matrix_phenos\n",
      "y = target_vals\n",
      "\n",
      "#determind CV folds\n",
      "cv_folds_indexnumbers = cross_validation.StratifiedKFold(y, n_folds=10)\n",
      "\n",
      "#define logreg model\n",
      "model_logistic_l2 = linear_model.LogisticRegression(penalty='l2')\n",
      "\n",
      "#define metrics\n",
      "mean_tpr = 0.0\n",
      "mean_fpr = np.linspace(0, 1, 100)\n",
      "all_tpr = []\n",
      "\n",
      "#OPEN FIGURE HANDLE\n",
      "fig = plt.figure(1)\n",
      "fig.set_size_inches(8,8)\n",
      "\n",
      "for i, (train_index, test_index) in enumerate(cv_folds_indexnumbers):\n",
      "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
      "    X_train, X_test = feature_matrix_phenos[train_index], feature_matrix_phenos[test_index]\n",
      "    y_train, y_test = target_vals[train_index], target_vals[test_index]\n",
      "\n",
      "    probas_ = model_logistic_l2.fit(X_train, y_train).predict_proba(X_test)\n",
      "    # Compute ROC curve and area the curve\n",
      "    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n",
      "    mean_tpr += interp(mean_fpr, fpr, tpr)\n",
      "    mean_tpr[0] = 0.0\n",
      "    roc_auc = auc(fpr, tpr)\n",
      "    #add plot to figure\n",
      "    plt.plot(fpr, tpr, lw=1, label='ROC fold %d (area = %0.2f)' % (i, roc_auc))\n",
      "    \n",
      "#add to figure\n",
      "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
      "\n",
      "#calculate mean TPR, AUC\n",
      "mean_tpr /= len(cv_folds_indexnumbers)\n",
      "mean_tpr[-1] = 1.0\n",
      "mean_auc = auc(mean_fpr, mean_tpr)\n",
      "\n",
      "#add supporting legends to figure\n",
      "plt.plot(mean_fpr, mean_tpr, 'k--',\n",
      "         label='Mean ROC (area = %0.2f)' % mean_auc, lw=2)\n",
      "\n",
      "plt.xlim([-0.05, 1.05])\n",
      "plt.ylim([-0.05, 1.05])\n",
      "plt.xlabel('False Positive Rate')\n",
      "plt.ylabel('True Positive Rate')\n",
      "plt.title('ROC: 10-fold CV Logistic Regression; MAP DECREASE BY 2mmHg; Gamma=[0.001, 0.04, 0.04]')\n",
      "plt.legend(loc=\"lower right\")\n",
      "#save figure\n",
      "save_filename = 'htn_marble_classification_MAPDECREASEBY2' + '_gamma_' + \"-\".join([str(g) for g in gammaForTF_used]) + '.png'\n",
      "fig.savefig(save_folder + save_filename)\n",
      "plt.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/nv/hcoc1/rchen87/anaconda/lib/python2.7/site-packages/sklearn/preprocessing/label.py:99: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
        "  y = column_or_1d(y, warn=True)\n",
        "/nv/hcoc1/rchen87/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.py:681: UserWarning: No negative samples in y_true, false positive value should be meaningless\n",
        "  warnings.warn(\"No negative samples in y_true, \"\n"
       ]
      },
      {
       "ename": "ValueError",
       "evalue": "Array contains NaN or infinity.",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-198-2d859b6a8f6f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0mmean_tpr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0minterp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mmean_tpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[1;31m#add plot to figure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlw\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'ROC fold %d (area = %0.2f)'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/nv/hcoc1/rchen87/anaconda/lib/python2.7/site-packages/sklearn/metrics/metrics.pyc\u001b[0m in \u001b[0;36mauc\u001b[1;34m(x, y, reorder)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \"\"\"\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         raise ValueError('At least 2 points are needed to compute'\n",
        "\u001b[1;32m/nv/hcoc1/rchen87/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_arrays\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m    231\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    232\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 233\u001b[1;33m                 \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0marray_orig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32m/nv/hcoc1/rchen87/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X)\u001b[0m\n\u001b[0;32m     25\u001b[0m     if (X.dtype.char in np.typecodes['AllFloat'] and not np.isfinite(X.sum())\n\u001b[0;32m     26\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Array contains NaN or infinity.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mValueError\u001b[0m: Array contains NaN or infinity."
       ]
      }
     ],
     "prompt_number": 198
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mean_fpr"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 199,
       "text": [
        "array([ 0.        ,  0.01010101,  0.02020202,  0.03030303,  0.04040404,\n",
        "        0.05050505,  0.06060606,  0.07070707,  0.08080808,  0.09090909,\n",
        "        0.1010101 ,  0.11111111,  0.12121212,  0.13131313,  0.14141414,\n",
        "        0.15151515,  0.16161616,  0.17171717,  0.18181818,  0.19191919,\n",
        "        0.2020202 ,  0.21212121,  0.22222222,  0.23232323,  0.24242424,\n",
        "        0.25252525,  0.26262626,  0.27272727,  0.28282828,  0.29292929,\n",
        "        0.3030303 ,  0.31313131,  0.32323232,  0.33333333,  0.34343434,\n",
        "        0.35353535,  0.36363636,  0.37373737,  0.38383838,  0.39393939,\n",
        "        0.4040404 ,  0.41414141,  0.42424242,  0.43434343,  0.44444444,\n",
        "        0.45454545,  0.46464646,  0.47474747,  0.48484848,  0.49494949,\n",
        "        0.50505051,  0.51515152,  0.52525253,  0.53535354,  0.54545455,\n",
        "        0.55555556,  0.56565657,  0.57575758,  0.58585859,  0.5959596 ,\n",
        "        0.60606061,  0.61616162,  0.62626263,  0.63636364,  0.64646465,\n",
        "        0.65656566,  0.66666667,  0.67676768,  0.68686869,  0.6969697 ,\n",
        "        0.70707071,  0.71717172,  0.72727273,  0.73737374,  0.74747475,\n",
        "        0.75757576,  0.76767677,  0.77777778,  0.78787879,  0.7979798 ,\n",
        "        0.80808081,  0.81818182,  0.82828283,  0.83838384,  0.84848485,\n",
        "        0.85858586,  0.86868687,  0.87878788,  0.88888889,  0.8989899 ,\n",
        "        0.90909091,  0.91919192,  0.92929293,  0.93939394,  0.94949495,\n",
        "        0.95959596,  0.96969697,  0.97979798,  0.98989899,  1.        ])"
       ]
      }
     ],
     "prompt_number": 199
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for x, y in cv_folds_indexnumbers:\n",
      "    print x\n",
      "    print y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n",
        "[   1    2    3 ..., 2518 2519 2520]\n",
        "[0]\n"
       ]
      }
     ],
     "prompt_number": 202
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 203,
       "text": [
        "array([0])"
       ]
      }
     ],
     "prompt_number": 203
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "target_vals"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 213,
       "text": [
        "array([[1],\n",
        "       [1],\n",
        "       [1],\n",
        "       ..., \n",
        "       [0],\n",
        "       [1],\n",
        "       [1]])"
       ]
      }
     ],
     "prompt_number": 213
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loaded_classDict.values()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 214,
       "text": [
        "[1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " 1,\n",
        " 1,\n",
        " 1,\n",
        " 0,\n",
        " 0,\n",
        " 1,\n",
        " 0,\n",
        " ...]"
       ]
      }
     ],
     "prompt_number": 214
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}