{
 "metadata": {
  "name": "",
  "signature": "sha256:cc2270d9216841ce1109c3ba5a1e7d65a63cd32225b93f18870145e4031641dd"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "\n",
      "tensor_input = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_tensors/htn-tensor-subsetforanalysis-20140811-{0}.dat'\n",
      "CODE_DIR = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/experiment_code/'\n",
      "marble_output_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/marble_output_files/'\n",
      "save_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/analyzeTensors_runClassification/'\n",
      "\n",
      "#load required modules:                                                                                                                                                                                                                                                                                           \n",
      "print \"loading required modules\"\n",
      "\n",
      "execfile( CODE_DIR + 'setup_python_env.py')\n",
      "pheWAS_xls_file = CODE_DIR + 'ICD9-2-PheWAS.xls'\n",
      "\n",
      "\n",
      "#create output folder if it does not exist                                                                                                                                                                                                                                                                        \n",
      "if not os.path.exists(save_folder):\n",
      "    os.makedirs(save_folder)\n",
      "\n",
      "############################################################################################################## \n",
      "\n",
      "#load pheWAS dictionary                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "xls = pd.ExcelFile(pheWAS_xls_file)\n",
      "df_pheWAS = xls.parse(xls.sheet_names[0])\n",
      "\n",
      "d_jdrange_lookup = dict(zip(list(df_pheWAS.JD_X_RANGE), list(df_pheWAS.JD_X_NAME)))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "loading required modules\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "##\n",
      "## For rest of the script, do the following:\n",
      "##    loop through all iterations where gamma was different, and grab phenotypes information from those\n",
      "##\n",
      "\n",
      "## load the tensor #######                                                                                                                                                                                                                                                                                        \n",
      "loaded_X, loaded_axisDict, loaded_classDict = tensorIO.loadSingleTensor(tensor_input)\n",
      "\n",
      "# the following are common to all ranges of gamma\n",
      "l_pts = loaded_axisDict[0].keys()\n",
      "l_jdrange = loaded_axisDict[1].keys()\n",
      "l_meds= loaded_axisDict[2].keys()\n",
      "\n",
      "# count the number of factors for both diagnoses / meds\n",
      "#   -- note: this is assuming we used same gamma for diagnoses as well as meds\n",
      "#\n",
      "l_gammas_used = [x*0.01 for x in range(1,16)]\n",
      "\n",
      "d_numfactors_pt_perGamma = dict()\n",
      "d_numfactors_diag_perGamma = dict()\n",
      "d_numfactors_med_perGamma = dict()\n",
      "\n",
      "d_numPheno_nonzero_pt_perGamma = dict()\n",
      "d_numPheno_nonzero_diag_perGamma = dict()\n",
      "d_numPheno_nonzero_med_perGamma = dict()\n",
      "\n",
      "for thisgamma in l_gammas_used:\n",
      "    #string for saving the file based upon gamma                                                                                                                                                                                                                                                                      \n",
      "    gammaForTF_used = [0.001, thisgamma, thisgamma]\n",
      "    gamma_str = '_gamma'\n",
      "    for num in gammaForTF_used:\n",
      "        gamma_str = gamma_str + '-' + str(num)\n",
      "    gamma_str = gamma_str + '.pickle'\n",
      "    \n",
      "    #filename for this set of gammas\n",
      "    filename_tensorFactors_thisgamma = marble_output_folder + \"pheno_htn_subset_analyzed_REG\" + gamma_str\n",
      "    filename_Yinfo_thisgamma = marble_output_folder + \"Yinfo_htn_subset_analyzed\" + gamma_str\n",
      "    \n",
      "    ##read in the pickles:                                                                                                                                                                                                                                                                                            \n",
      "    matrix_pkl = open(filename_tensorFactors_thisgamma, \"rb\")\n",
      "    pheno_htn_subset_analyzed_REG_withGamma = pickle.load(matrix_pkl)\n",
      "    matrix_pkl.close()\n",
      "\n",
      "    matrix_pkl = open(filename_Yinfo_thisgamma, \"rb\")\n",
      "    Yinfo_htn_subset_analyzed_withGamma = pickle.load(matrix_pkl)\n",
      "    matrix_pkl.close()\n",
      "\n",
      "    #tensor with all phenotypes (factorization)                                                                                                                                                                                                                                                                       \n",
      "    ktensor_phenotypes = pheno_htn_subset_analyzed_REG_withGamma[0]\n",
      "\n",
      "    #sort phenotypes by lambda values:                                                                                                                                                                                                                                                                                \n",
      "    d_lambda_phenoNumber = OrderedDict(zip( list(range(ktensor_phenotypes.R)),\n",
      "                                        list(ktensor_phenotypes.lmbda)\n",
      "                                        ))\n",
      "    l_phenoNumbers_sorted_by_lambda = [tup[0] for tup in sorted(d_lambda_phenoNumber.iteritems(), key=operator.itemgetter(1))][::-1]  #get a sorted list of phenotype numbers, which are sorted by using the operator.itemgetter                                                                                      \n",
      "    \n",
      "    # loop through phenotypes and count how many diagnosis / meds there are for each phenotype\n",
      "    l_numfactors_pt = []\n",
      "    l_numfactors_jdrange = []\n",
      "    l_numfactors_med = []\n",
      "    for i in l_phenoNumbers_sorted_by_lambda:\n",
      "        this_pheno_pt_factor = ktensor_phenotypes.U[0][:,i]\n",
      "        this_pheno_jdrange_factor = ktensor_phenotypes.U[1][:,i]\n",
      "        this_pheno_med_factor = ktensor_phenotypes.U[2][:,i]\n",
      "    \n",
      "        this_pheno_pt_nnz = np.nonzero(this_pheno_pt_factor)[0]\n",
      "        this_pheno_jdrange_nnz = np.nonzero(this_pheno_jdrange_factor)[0]\n",
      "        this_pheno_med_nnz = np.nonzero(this_pheno_med_factor)[0]\n",
      "        \n",
      "        num_pt = len(this_pheno_pt_nnz)\n",
      "        num_jdrange = len(this_pheno_jdrange_nnz)\n",
      "        num_med = len(this_pheno_med_nnz)\n",
      "    \n",
      "        l_numfactors_pt.append(num_pt)\n",
      "        l_numfactors_jdrange.append(num_jdrange)\n",
      "        l_numfactors_med.append(num_med)\n",
      "    \n",
      "    d_numfactors_pt_perGamma[thisgamma] = np.array(l_numfactors_pt)[np.mean(np.nonzero(l_numfactors_pt))]\n",
      "    d_numfactors_diag_perGamma[thisgamma] = np.array(l_numfactors_jdrange)[np.mean(np.nonzero(l_numfactors_jdrange))]\n",
      "    d_numfactors_med_perGamma[thisgamma] = np.array(l_numfactors_med)[np.mean(np.nonzero(l_numfactors_med))]\n",
      "    d_numPheno_nonzero_pt_perGamma[thisgamma] = len(np.nonzero(l_numfactors_pt))\n",
      "    d_numPheno_nonzero_diag_perGamma[thisgamma] = len(np.nonzero(l_numfactors_jdrange))\n",
      "    d_numPheno_nonzero_med_perGamma[thisgamma] = len(np.nonzero(l_numfactors_med))\n",
      "        \n",
      "od_numfactors_pt_perGamma = OrderedDict(sorted(d_numfactors_pt_perGamma.items()))\n",
      "od_numfactors_diag_perGamma = OrderedDict(sorted(d_numfactors_diag_perGamma.items()))\n",
      "od_numfactors_med_perGamma = OrderedDict(sorted(d_numfactors_med_perGamma.items()))\n",
      "od_numPheno_nonzero_pt_perGamma = OrderedDict(sorted(d_numPheno_nonzero_pt_perGamma.items()))\n",
      "od_numPheno_nonzero_diag_perGamma = OrderedDict(sorted(d_numPheno_nonzero_diag_perGamma.items()))\n",
      "od_numPheno_nonzero_med_perGamma = OrderedDict(sorted(d_numPheno_nonzero_med_perGamma.items()))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:52: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:53: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
        "-c:54: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
       ]
      }
     ],
     "prompt_number": 100
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure(1)\n",
      "fig.set_size_inches(8,8)\n",
      "plt.plot(od_numfactors_pt_perGamma.keys(), od_numfactors_pt_perGamma.values() , 'bs')\n",
      "plt.xlabel('gamma value')\n",
      "plt.ylabel('Count')\n",
      "plt.title('Patient factor')\n",
      "fig.savefig(save_folder + 'htn_marble_ptMode_gamma_factorElementCount.png')\n",
      "plt.close()\n",
      "\n",
      "fig = plt.figure(2)\n",
      "fig.set_size_inches(8,8)\n",
      "plt.plot(od_numfactors_diag_perGamma.keys(), od_numfactors_diag_perGamma.values() , 'bs')\n",
      "plt.xlabel('gamma value')\n",
      "plt.ylabel('Count')\n",
      "plt.title('Diagnosis factor')\n",
      "fig.savefig(save_folder + 'htn_marble_diagMode_gamma_factorElementCount.png')\n",
      "plt.close()\n",
      "\n",
      "fig = plt.figure(3)\n",
      "fig.set_size_inches(8,8)\n",
      "plt.plot(od_numfactors_med_perGamma.keys(), od_numfactors_med_perGamma.values() , 'bs')\n",
      "plt.xlabel('gamma value for diagnosis / meds modes')\n",
      "plt.ylabel('Count')\n",
      "plt.title('Medication factor')\n",
      "fig.savefig(save_folder + 'htn_marble_medMode_gamma_factorElementCount.png')\n",
      "plt.close()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 104
    }
   ],
   "metadata": {}
  }
 ]
}