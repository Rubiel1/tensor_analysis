{
 "metadata": {
  "name": "",
  "signature": "sha256:ec62b7736a1cb71fbe67f3e0a3cd44b31c14eb3895e66f3a213d31fc5ac095eb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "#fdsafdas.txt#     build_sparse_tensor_from_mht_data.py  create_drug_dict_RxNorm.py~                        parse_MEDS_MHT_subset.py             resume_reloadTensors_localadmin.py         setup_python_env.py                       wrapper_marble_localadmin.py~\r\n",
        "#fdsafdsaf.py#     create_drug_dict.py                   create_subset_of_allfinite_tensor_forAnalysis.py   parse_MEDS_MHT_subset_localadmin.py  run_analyze_marble_gamma-0.12to0.15.ipynb  sh_wrapper_tensor_experiemnts_marble.sh\r\n",
        "ICD9-2-PheWAS.xls  create_drug_dict.py~                  create_subset_of_allfinite_tensor_forAnalysis.py~  read_pheWAS_dictionary_xls.py        run_factorization_localadmin.py            sh_wrapper_tensor_experiemnts_marble.sh~\r\n",
        "Untitled0.ipynb    create_drug_dict_RxNorm.py            lookupDrug_modRC.py                                read_pheWAS_dictionary_xls.py~       \u001b[0m\u001b[01;34mscrape_drugs_joyce\u001b[0m/                        wrapper_marble_localadmin.py\r\n",
        "\u001b[m"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import os\n",
      "os.getcwd()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 3,
       "text": [
        "'/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_process_server_backup_20140828'"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir('/nv/pcoc1/rchen87/tensor_factorization/github_tensor/experiment_code/')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "ICD9-2-PheWAS.xls  loadtensor_runfactorization_printphenotypes.py  loadtensor_runfactorization_printphenotypes.py~  read_pheWAS_dictionary_xls.py  read_pheWAS_dictionary_xls.py~  setup_python_env.py  setup_python_env.py~  test_python.py  test_python.py~\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ls -l"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "total 4012\r\n",
        "-rw-r--r-- 1 rchen87 cc-song 3941376 Aug 29 01:08 ICD9-2-PheWAS.xls\r\n",
        "-rw-r--r-- 1 rchen87 cc-song    9319 Aug 29 02:01 loadtensor_runfactorization_printphenotypes.py\r\n",
        "-rw-r--r-- 1 rchen87 cc-song    9242 Aug 29 01:58 loadtensor_runfactorization_printphenotypes.py~\r\n",
        "-rw-r--r-- 1 rchen87 cc-song     664 Aug 29 01:53 read_pheWAS_dictionary_xls.py\r\n",
        "-rw-r--r-- 1 rchen87 cc-song     846 Aug 29 01:52 read_pheWAS_dictionary_xls.py~\r\n",
        "-rw-r--r-- 1 rchen87 cc-song    1462 Aug 29 01:46 setup_python_env.py\r\n",
        "-rw-r--r-- 1 rchen87 cc-song    1445 Aug 29 01:03 setup_python_env.py~\r\n",
        "-rw-r--r-- 1 rchen87 cc-song     125 Aug 29 01:33 test_python.py\r\n",
        "-rw-r--r-- 1 rchen87 cc-song     107 Aug 29 01:33 test_python.py~\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "# R = int(sys.argv[1])\n",
      "# alpha = float(sys.argv[2])\n",
      "# gammaForTF = sys.argv[3]\n",
      "# tensor_input = sys.argv[4]\n",
      "# CODE_DIR = sys.argv[5]\n",
      "# save_folder = sys.argv[6]\n",
      "\n",
      "R = 50\n",
      "alpha = 1\n",
      "gammaForTF = '0.001,0.14,0.14'\n",
      "tensor_input = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_tensors/htn-tensor-subsetforanalysis-20140811-{0}.dat'\n",
      "CODE_DIR = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/experiment_code/'\n",
      "save_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/output_20140829/'\n",
      "\n",
      "\n",
      "gammaForTF = gammaForTF.split(',')\n",
      "gammaForTF = [float(x) for x in gammaForTF]\n",
      "\n",
      "\n",
      "#load required modules:                                                                                                                                                                                                                                                                                           \n",
      "print \"loading required modules\"\n",
      "\n",
      "execfile( CODE_DIR + 'setup_python_env.py')\n",
      "pheWAS_xls_file = CODE_DIR + 'ICD9-2-PheWAS.xls'\n",
      "\n",
      "\n",
      "#create output folder if it does not exist                                                                                                                                                                                                                                                                        \n",
      "if not os.path.exists(save_folder):\n",
      "    os.makedirs(save_folder)\n",
      "\n",
      "#do tensor factorization on the SUBSET - with GAMMA as set above ##################################################################################################                                                                                                                                               \n",
      "#laod the tensor for the subset!                                                                                                                                                                                                                                                                                  \n",
      "print \"loading tensor data\"\n",
      "\n",
      "loaded_X, loaded_axisDict, loaded_classDict = tensorIO.loadSingleTensor(tensor_input)\n",
      "\n",
      "startTime = time.time()#start time -- to time it                                                                                                                                                                                                                                                                  \n",
      "##factorization                                                                                                                                                                                                                                                                                                   \n",
      "print \"running factorization\"\n",
      "spntf_htn_subset_analyzed_withGamma = SP_NTF.SP_NTF(loaded_X, R=R, alpha=alpha)\n",
      "Yinfo_htn_subset_analyzed_withGamma = spntf_htn_subset_analyzed_withGamma.computeDecomp(gamma=gammaForTF)\n",
      "marbleElapse = time.time() - startTime #elapsed time                                                                                                                                                                                                                                                              \n",
      "\n",
      "#tensor decomposition factors (\"phenotypes\"):                                                                                                                                                                                                                                                                     \n",
      "pheno_htn_subset_analyzed_withGamma_REG = spntf_htn_subset_analyzed_withGamma.M[0]\n",
      "pheno_htn_subset_analyzed_withGamma_AUG = spntf_htn_subset_analyzed_withGamma.M[1]\n",
      "pheno_htn_subset_analyzed_withGamma = (pheno_htn_subset_analyzed_withGamma_REG, pheno_htn_subset_analyzed_withGamma_AUG)\n",
      "\n",
      "\n",
      "#string for saving the file based upon gamma                                                                                                                                                                                                                                                                      \n",
      "gamma_str = '_gamma'\n",
      "for num in gammaForTF:\n",
      "    gamma_str = gamma_str + '-' + str(num)\n",
      "gamma_str = gamma_str + '.pickle'\n",
      "\n",
      "#save factorization in pickle                                                                                                                                                                                                                                                                                     \n",
      "outfile_str = save_folder + \"pheno_htn_subset_analyzed_REG\" + gamma_str\n",
      "with open(outfile_str, \"wb\") as output_file: ##IMPT! phenotype stored in this pickle                                                                                                                                                                                                                              \n",
      "    pickle.dump(pheno_htn_subset_analyzed_withGamma, output_file)\n",
      "output_file.close()\n",
      "outfile_str = save_folder + \"pheno_htn_subset_analyzed_AUG\" + gamma_str\n",
      "with open(outfile_str, \"wb\") as output_file: ##IMPT! phenotype stored in this pickle                                                                                                                                                                                                                              \n",
      "    pickle.dump(pheno_htn_subset_analyzed_withGamma, output_file)\n",
      "output_file.close()\n",
      "outfile_str = save_folder + \"Yinfo_htn_subset_analyzed\" + gamma_str\n",
      "with open(outfile_str, \"wb\") as output_file:\n",
      "    pickle.dump(Yinfo_htn_subset_analyzed_withGamma, output_file)\n",
      "output_file.close()\n",
      "\n",
      "\n",
      "import operator\n",
      "\n",
      "def calculateValues(TM, M):\n",
      "    fms = TM.greedy_fms(M)\n",
      "    fos = TM.greedy_fos(M)\n",
      "    nnz = tensorTools.countTensorNNZ(M)\n",
      "    return fms, fos, nnz\n",
      "\n",
      "## load the tensor #######                                                                                                                                                                                                                                                                                        \n",
      "loaded_X, loaded_axisDict, loaded_classDict = tensorIO.loadSingleTensor(tensor_input)\n",
      "\n",
      "##read in the pickles:                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "outfile_str = save_folder + \"pheno_htn_subset_analyzed_REG\" + gamma_str\n",
      "matrix_pkl = open(outfile_str, \"rb\")\n",
      "pheno_htn_subset_analyzed_REG_withGamma = pickle.load(matrix_pkl)\n",
      "matrix_pkl.close()\n",
      "\n",
      "outfile_str = save_folder + \"Yinfo_htn_subset_analyzed\" + gamma_str\n",
      "matrix_pkl = open(outfile_str, \"rb\")\n",
      "Yinfo_htn_subset_analyzed_withGamma = pickle.load(matrix_pkl)\n",
      "matrix_pkl.close()\n",
      "\n",
      "#write output file                                                                                                                                                                                                                                                                                                \n",
      "pheno_outstream = open(save_folder + \"phenotypes\"+gamma_str+\".out\", 'w+')\n",
      "\n",
      "\n",
      "############################################################################################################## \n",
      "\n",
      "#load pheWAS dictionary                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "xls = pd.ExcelFile(pheWAS_xls_file)\n",
      "df_pheWAS = xls.parse(xls.sheet_names[0])\n",
      "\n",
      "d_jdrange_lookup = dict(zip(list(df_pheWAS.JD_X_RANGE), list(df_pheWAS.JD_X_NAME)))\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################################                                                                                                                                                                                                     \n",
      "\n",
      "\n",
      "#tensor with all phenotypes (factorization)                                                                                                                                                                                                                                                                       \n",
      "ktensor_phenotypes = pheno_htn_subset_analyzed_REG_withGamma[0]\n",
      "l_pts = loaded_axisDict[0].keys()\n",
      "l_jdrange = loaded_axisDict[1].keys()\n",
      "l_meds= loaded_axisDict[2].keys()\n",
      "\n",
      "#will store all the data                                                                                                                                                                                                                                                                                          \n",
      "d_pheno_nonzero_labels = OrderedDict()\n",
      "\n",
      "\n",
      "#sort phenotypes by lambda values:                                                                                                                                                                                                                                                                                \n",
      "d_lambda_phenoNumber = OrderedDict(zip( list(range(R)),\n",
      "                                        list(ktensor_phenotypes.lmbda)\n",
      "                                        ))\n",
      "l_phenoNumbers_sorted_by_lambda = [tup[0] for tup in sorted(d_lambda_phenoNumber.iteritems(), key=operator.itemgetter(1))][::-1]  #get a sorted list of phenotype numbers, which are sorted by using the operator.itemgetter                                                                                      \n",
      "\n",
      "#print phenotype feature names #################                                                                                                                                                                                                                                                                  \n",
      "#for i in range(10):                                                 \n",
      "for i in l_phenoNumbers_sorted_by_lambda:\n",
      "    print \"===== phenotype \" + str(i) + \"=================================================================\"\n",
      "    pheno_outstream.write(\"===== phenotype \" + str(i) + \"=================================================================\" + '\\n')\n",
      "    this_lmbda = ktensor_phenotypes.lmbda[i]\n",
      "    this_pheno_pt_factor = ktensor_phenotypes.U[0][:,i]\n",
      "    this_pheno_jdrange_factor = ktensor_phenotypes.U[1][:,i]\n",
      "    this_pheno_med_factor = ktensor_phenotypes.U[2][:,i]\n",
      "\n",
      "    this_pheno_pt_nnz = np.nonzero(this_pheno_pt_factor)[0]\n",
      "    this_pheno_jdrange_nnz = np.nonzero(this_pheno_jdrange_factor)[0]\n",
      "    this_pheno_med_nnz = np.nonzero(this_pheno_med_factor)[0]\n",
      "\n",
      "    l_nonzero_pt_thisPheno = []\n",
      "    l_nonzero_meds_thisPheno = []\n",
      "    l_nonzero_jdrange_thisPheno = []\n",
      "    l_nonzero_jdrange_names_thisPheno = []\n",
      "\n",
      "    for j in this_pheno_pt_nnz:\n",
      "        l_nonzero_pt_thisPheno.append(l_pts[j])\n",
      "    for j in this_pheno_jdrange_nnz:\n",
      "        l_nonzero_jdrange_thisPheno.append(l_jdrange[j])\n",
      "        l_nonzero_jdrange_names_thisPheno.append(d_jdrange_lookup[l_jdrange[j]])\n",
      "    for j in this_pheno_med_nnz:\n",
      "        l_nonzero_meds_thisPheno.append(l_meds[j])\n",
      "\n",
      "    #data                                                                                                                                                                                                                                                                                                         \n",
      "    d_pheno_nonzero_labels[i] = dict() #for phenotype i                                                                                                                                                                                                                                                           \n",
      "    d_pheno_nonzero_labels[i]['LAMBDA'] = this_lmbda #lambda value                                                                                                                                                                                                                                                \n",
      "    d_pheno_nonzero_labels[i]['PERCENT_PTS'] = len(l_nonzero_pt_thisPheno) / float(len(this_pheno_pt_factor))\n",
      "    d_pheno_nonzero_labels[i]['MEDS_NZ'] = l_nonzero_meds_thisPheno #for phenotype i                                                                                                                                                                                                                              \n",
      "    d_pheno_nonzero_labels[i]['JDRANGE_NZ'] = l_nonzero_jdrange_thisPheno #for phenotype i                                                                                                                                                                                                                        \n",
      "    d_pheno_nonzero_labels[i]['JDRANGE_NAMES_NZ'] = l_nonzero_jdrange_names_thisPheno #for phenotype i                                                                                                                                                                                                            \n",
      "\n",
      "    print \"proportion of pts: \" + str(d_pheno_nonzero_labels[i]['PERCENT_PTS'])\n",
      "    pheno_outstream.write(\"proportion of pts: \" + str(d_pheno_nonzero_labels[i]['PERCENT_PTS']) + '\\n')\n",
      "    print \"lambda: \" + str(this_lmbda)\n",
      "    pheno_outstream.write(\"lambda: \" + str(this_lmbda) + '\\n')\n",
      "\n",
      "\n",
      "    print \"----------------------------------------\" #divider                                                                                                                                                                                                                                                     \n",
      "    pheno_outstream.write(\"----------------------------------------\" + '\\n')\n",
      "    #make ranking of JDRANGE by the weights:                                                                                                                                                                                                                                                                      \n",
      "    nparr_jdrange_weights = this_pheno_jdrange_factor[this_pheno_jdrange_nnz]\n",
      "    d_jdrangeindex_weights = OrderedDict(zip(this_pheno_jdrange_nnz, nparr_jdrange_weights))\n",
      "    l_jdrangeindex_sorted = [tup[0] for tup in sorted(d_jdrangeindex_weights.iteritems(), key=operator.itemgetter(1))][::-1] #note: use slice [::-1] to reverse list!                                                                                                                                             \n",
      "    for index_this_jdrange in l_jdrangeindex_sorted:\n",
      "        print d_jdrange_lookup[l_jdrange[index_this_jdrange]] + '\\t' + str(\"%.3f\" %this_pheno_jdrange_factor[index_this_jdrange] )\n",
      "        pheno_outstream.write(str(d_jdrange_lookup[l_jdrange[index_this_jdrange]]) + '\\t' + str(\"%.3f\" %this_pheno_jdrange_factor[index_this_jdrange])  +'\\n')\n",
      "\n",
      "\n",
      "    print \"----------------------------------------\" #divider between diagnostic codes and meds                                                                                                                                                                                                                   \n",
      "    pheno_outstream.write(\"----------------------------------------\" + '\\n')\n",
      "    #make ranking of MED by the weights:                                                                                                                                                                                                                                                                          \n",
      "    nparr_med_weights = this_pheno_med_factor[this_pheno_med_nnz]\n",
      "    d_medindex_weights = OrderedDict(zip(this_pheno_med_nnz, nparr_med_weights))\n",
      "    l_medindex_sorted = [tup[0] for tup in sorted(d_medindex_weights.iteritems(), key=operator.itemgetter(1))][::-1]\n",
      "    for index_this_med in l_medindex_sorted:\n",
      "        print l_meds[index_this_med]  + '\\t' + str(\"%.3f\" %this_pheno_med_factor[index_this_med])\n",
      "        pheno_outstream.write(l_meds[index_this_med]  + '\\t' + str(\"%.3f\" %this_pheno_med_factor[index_this_med]) + '\\n')\n",
      "pheno_outstream.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sys\n",
      "# R = int(sys.argv[1])\n",
      "# alpha = float(sys.argv[2])\n",
      "# gammaForTF = sys.argv[3]\n",
      "# tensor_input = sys.argv[4]\n",
      "# CODE_DIR = sys.argv[5]\n",
      "# save_folder = sys.argv[6]\n",
      "\n",
      "R = 50\n",
      "alpha = 1\n",
      "gammaForTF = '0.001,0.15,0.15'\n",
      "tensor_input = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_data_tensors/htn-tensor-subsetforanalysis-20140811-{0}.dat'\n",
      "CODE_DIR = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/experiment_code/'\n",
      "save_folder = '/nv/pcoc1/rchen87/tensor_factorization/github_tensor/htn_expt_run/output_20140829/'\n",
      "\n",
      "\n",
      "gammaForTF = gammaForTF.split(',')\n",
      "gammaForTF = [float(x) for x in gammaForTF]\n",
      "\n",
      "\n",
      "#load required modules:                                                                                                                                                                                                                                                                                           \n",
      "print \"loading required modules\"\n",
      "\n",
      "execfile( CODE_DIR + 'setup_python_env.py')\n",
      "pheWAS_xls_file = CODE_DIR + 'ICD9-2-PheWAS.xls'\n",
      "\n",
      "\n",
      "#create output folder if it does not exist                                                                                                                                                                                                                                                                        \n",
      "if not os.path.exists(save_folder):\n",
      "    os.makedirs(save_folder)\n",
      "\n",
      "#do tensor factorization on the SUBSET - with GAMMA as set above ##################################################################################################                                                                                                                                               \n",
      "#laod the tensor for the subset!                                                                                                                                                                                                                                                                                  \n",
      "print \"loading tensor data\"\n",
      "\n",
      "loaded_X, loaded_axisDict, loaded_classDict = tensorIO.loadSingleTensor(tensor_input)\n",
      "\n",
      "startTime = time.time()#start time -- to time it                                                                                                                                                                                                                                                                  \n",
      "##factorization                                                                                                                                                                                                                                                                                                   \n",
      "print \"running factorization\"\n",
      "spntf_htn_subset_analyzed_withGamma = SP_NTF.SP_NTF(loaded_X, R=R, alpha=alpha)\n",
      "Yinfo_htn_subset_analyzed_withGamma = spntf_htn_subset_analyzed_withGamma.computeDecomp(gamma=gammaForTF)\n",
      "marbleElapse = time.time() - startTime #elapsed time                                                                                                                                                                                                                                                              \n",
      "\n",
      "#tensor decomposition factors (\"phenotypes\"):                                                                                                                                                                                                                                                                     \n",
      "pheno_htn_subset_analyzed_withGamma_REG = spntf_htn_subset_analyzed_withGamma.M[0]\n",
      "pheno_htn_subset_analyzed_withGamma_AUG = spntf_htn_subset_analyzed_withGamma.M[1]\n",
      "pheno_htn_subset_analyzed_withGamma = (pheno_htn_subset_analyzed_withGamma_REG, pheno_htn_subset_analyzed_withGamma_AUG)\n",
      "\n",
      "\n",
      "#string for saving the file based upon gamma                                                                                                                                                                                                                                                                      \n",
      "gamma_str = '_gamma'\n",
      "for num in gammaForTF:\n",
      "    gamma_str = gamma_str + '-' + str(num)\n",
      "gamma_str = gamma_str + '.pickle'\n",
      "\n",
      "#save factorization in pickle                                                                                                                                                                                                                                                                                     \n",
      "outfile_str = save_folder + \"pheno_htn_subset_analyzed_REG\" + gamma_str\n",
      "with open(outfile_str, \"wb\") as output_file: ##IMPT! phenotype stored in this pickle                                                                                                                                                                                                                              \n",
      "    pickle.dump(pheno_htn_subset_analyzed_withGamma, output_file)\n",
      "output_file.close()\n",
      "outfile_str = save_folder + \"pheno_htn_subset_analyzed_AUG\" + gamma_str\n",
      "with open(outfile_str, \"wb\") as output_file: ##IMPT! phenotype stored in this pickle                                                                                                                                                                                                                              \n",
      "    pickle.dump(pheno_htn_subset_analyzed_withGamma, output_file)\n",
      "output_file.close()\n",
      "outfile_str = save_folder + \"Yinfo_htn_subset_analyzed\" + gamma_str\n",
      "with open(outfile_str, \"wb\") as output_file:\n",
      "    pickle.dump(Yinfo_htn_subset_analyzed_withGamma, output_file)\n",
      "output_file.close()\n",
      "\n",
      "\n",
      "import operator\n",
      "\n",
      "def calculateValues(TM, M):\n",
      "    fms = TM.greedy_fms(M)\n",
      "    fos = TM.greedy_fos(M)\n",
      "    nnz = tensorTools.countTensorNNZ(M)\n",
      "    return fms, fos, nnz\n",
      "\n",
      "## load the tensor #######                                                                                                                                                                                                                                                                                        \n",
      "loaded_X, loaded_axisDict, loaded_classDict = tensorIO.loadSingleTensor(tensor_input)\n",
      "\n",
      "##read in the pickles:                                                                                                                                                                                                                                                                                            \n",
      "\n",
      "outfile_str = save_folder + \"pheno_htn_subset_analyzed_REG\" + gamma_str\n",
      "matrix_pkl = open(outfile_str, \"rb\")\n",
      "pheno_htn_subset_analyzed_REG_withGamma = pickle.load(matrix_pkl)\n",
      "matrix_pkl.close()\n",
      "\n",
      "outfile_str = save_folder + \"Yinfo_htn_subset_analyzed\" + gamma_str\n",
      "matrix_pkl = open(outfile_str, \"rb\")\n",
      "Yinfo_htn_subset_analyzed_withGamma = pickle.load(matrix_pkl)\n",
      "matrix_pkl.close()\n",
      "\n",
      "#write output file                                                                                                                                                                                                                                                                                                \n",
      "pheno_outstream = open(save_folder + \"phenotypes\"+gamma_str+\".out\", 'w+')\n",
      "\n",
      "\n",
      "############################################################################################################## \n",
      "\n",
      "#load pheWAS dictionary                                                                                                                                                                                                                                                                                           \n",
      "\n",
      "xls = pd.ExcelFile(pheWAS_xls_file)\n",
      "df_pheWAS = xls.parse(xls.sheet_names[0])\n",
      "\n",
      "d_jdrange_lookup = dict(zip(list(df_pheWAS.JD_X_RANGE), list(df_pheWAS.JD_X_NAME)))\n",
      "\n",
      "\n",
      "\n",
      "#############################################################################################################                                                                                                                                                                                                     \n",
      "\n",
      "\n",
      "#tensor with all phenotypes (factorization)                                                                                                                                                                                                                                                                       \n",
      "ktensor_phenotypes = pheno_htn_subset_analyzed_REG_withGamma[0]\n",
      "l_pts = loaded_axisDict[0].keys()\n",
      "l_jdrange = loaded_axisDict[1].keys()\n",
      "l_meds= loaded_axisDict[2].keys()\n",
      "\n",
      "#will store all the data                                                                                                                                                                                                                                                                                          \n",
      "d_pheno_nonzero_labels = OrderedDict()\n",
      "\n",
      "\n",
      "#sort phenotypes by lambda values:                                                                                                                                                                                                                                                                                \n",
      "d_lambda_phenoNumber = OrderedDict(zip( list(range(R)),\n",
      "                                        list(ktensor_phenotypes.lmbda)\n",
      "                                        ))\n",
      "l_phenoNumbers_sorted_by_lambda = [tup[0] for tup in sorted(d_lambda_phenoNumber.iteritems(), key=operator.itemgetter(1))][::-1]  #get a sorted list of phenotype numbers, which are sorted by using the operator.itemgetter                                                                                      \n",
      "\n",
      "#print phenotype feature names #################                                                                                                                                                                                                                                                                  \n",
      "#for i in range(10):                                                 \n",
      "for i in l_phenoNumbers_sorted_by_lambda:\n",
      "    print \"===== phenotype \" + str(i) + \"=================================================================\"\n",
      "    pheno_outstream.write(\"===== phenotype \" + str(i) + \"=================================================================\" + '\\n')\n",
      "    this_lmbda = ktensor_phenotypes.lmbda[i]\n",
      "    this_pheno_pt_factor = ktensor_phenotypes.U[0][:,i]\n",
      "    this_pheno_jdrange_factor = ktensor_phenotypes.U[1][:,i]\n",
      "    this_pheno_med_factor = ktensor_phenotypes.U[2][:,i]\n",
      "\n",
      "    this_pheno_pt_nnz = np.nonzero(this_pheno_pt_factor)[0]\n",
      "    this_pheno_jdrange_nnz = np.nonzero(this_pheno_jdrange_factor)[0]\n",
      "    this_pheno_med_nnz = np.nonzero(this_pheno_med_factor)[0]\n",
      "\n",
      "    l_nonzero_pt_thisPheno = []\n",
      "    l_nonzero_meds_thisPheno = []\n",
      "    l_nonzero_jdrange_thisPheno = []\n",
      "    l_nonzero_jdrange_names_thisPheno = []\n",
      "\n",
      "    for j in this_pheno_pt_nnz:\n",
      "        l_nonzero_pt_thisPheno.append(l_pts[j])\n",
      "    for j in this_pheno_jdrange_nnz:\n",
      "        l_nonzero_jdrange_thisPheno.append(l_jdrange[j])\n",
      "        l_nonzero_jdrange_names_thisPheno.append(d_jdrange_lookup[l_jdrange[j]])\n",
      "    for j in this_pheno_med_nnz:\n",
      "        l_nonzero_meds_thisPheno.append(l_meds[j])\n",
      "\n",
      "    #data                                                                                                                                                                                                                                                                                                         \n",
      "    d_pheno_nonzero_labels[i] = dict() #for phenotype i                                                                                                                                                                                                                                                           \n",
      "    d_pheno_nonzero_labels[i]['LAMBDA'] = this_lmbda #lambda value                                                                                                                                                                                                                                                \n",
      "    d_pheno_nonzero_labels[i]['PERCENT_PTS'] = len(l_nonzero_pt_thisPheno) / float(len(this_pheno_pt_factor))\n",
      "    d_pheno_nonzero_labels[i]['MEDS_NZ'] = l_nonzero_meds_thisPheno #for phenotype i                                                                                                                                                                                                                              \n",
      "    d_pheno_nonzero_labels[i]['JDRANGE_NZ'] = l_nonzero_jdrange_thisPheno #for phenotype i                                                                                                                                                                                                                        \n",
      "    d_pheno_nonzero_labels[i]['JDRANGE_NAMES_NZ'] = l_nonzero_jdrange_names_thisPheno #for phenotype i                                                                                                                                                                                                            \n",
      "\n",
      "    print \"proportion of pts: \" + str(d_pheno_nonzero_labels[i]['PERCENT_PTS'])\n",
      "    pheno_outstream.write(\"proportion of pts: \" + str(d_pheno_nonzero_labels[i]['PERCENT_PTS']) + '\\n')\n",
      "    print \"lambda: \" + str(this_lmbda)\n",
      "    pheno_outstream.write(\"lambda: \" + str(this_lmbda) + '\\n')\n",
      "\n",
      "\n",
      "    print \"----------------------------------------\" #divider                                                                                                                                                                                                                                                     \n",
      "    pheno_outstream.write(\"----------------------------------------\" + '\\n')\n",
      "    #make ranking of JDRANGE by the weights:                                                                                                                                                                                                                                                                      \n",
      "    nparr_jdrange_weights = this_pheno_jdrange_factor[this_pheno_jdrange_nnz]\n",
      "    d_jdrangeindex_weights = OrderedDict(zip(this_pheno_jdrange_nnz, nparr_jdrange_weights))\n",
      "    l_jdrangeindex_sorted = [tup[0] for tup in sorted(d_jdrangeindex_weights.iteritems(), key=operator.itemgetter(1))][::-1] #note: use slice [::-1] to reverse list!                                                                                                                                             \n",
      "    for index_this_jdrange in l_jdrangeindex_sorted:\n",
      "        print d_jdrange_lookup[l_jdrange[index_this_jdrange]] + '\\t' + str(\"%.3f\" %this_pheno_jdrange_factor[index_this_jdrange] )\n",
      "        pheno_outstream.write(str(d_jdrange_lookup[l_jdrange[index_this_jdrange]]) + '\\t' + str(\"%.3f\" %this_pheno_jdrange_factor[index_this_jdrange])  +'\\n')\n",
      "\n",
      "\n",
      "    print \"----------------------------------------\" #divider between diagnostic codes and meds                                                                                                                                                                                                                   \n",
      "    pheno_outstream.write(\"----------------------------------------\" + '\\n')\n",
      "    #make ranking of MED by the weights:                                                                                                                                                                                                                                                                          \n",
      "    nparr_med_weights = this_pheno_med_factor[this_pheno_med_nnz]\n",
      "    d_medindex_weights = OrderedDict(zip(this_pheno_med_nnz, nparr_med_weights))\n",
      "    l_medindex_sorted = [tup[0] for tup in sorted(d_medindex_weights.iteritems(), key=operator.itemgetter(1))][::-1]\n",
      "    for index_this_med in l_medindex_sorted:\n",
      "        print l_meds[index_this_med]  + '\\t' + str(\"%.3f\" %this_pheno_med_factor[index_this_med])\n",
      "        pheno_outstream.write(l_meds[index_this_med]  + '\\t' + str(\"%.3f\" %this_pheno_med_factor[index_this_med]) + '\\n')\n",
      "pheno_outstream.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}